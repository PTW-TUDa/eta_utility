# Setup pip cache so that it can be reused between jobs
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip_cache"
  GIT_CLEAN_FLAGS: -x -f -e .pip_cache/** -e venv/**

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: ($CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "development")
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never

include:
  - template: Security/Secret-Detection.gitlab-ci.yml
  - template: Security/License-Scanning.gitlab-ci.yml

stages:
  - setup
  - check
  - test
  - deploy

default:
  tags:
    - python
    - docker

  image: python:3.7

  before_script:
    - python -V  # Print out python version for debugging
    - python3 -m venv venv
    - source venv/bin/activate
    - pip install --upgrade pip
    - pip install .[eta_x]

  # Make sure that the installation is cached between jobs
  cache:
    key: $CI_PROJECT_ID
    paths:
      - .pip_cache
      - venv
    policy: pull

create_cache:
  stage: setup
  script: pip install isort black==21.6b0 flakehell pytest pytest-cov
  cache:
    policy: pull-push

isort:
  stage: check
  script:
    - pip install isort
    - isort -c -v .

black:
  stage: check
  script:
    - pip install black==21.6b0
    - black --check --config pyproject.toml eta_utility/ test/

flakehell:
  stage: check
  script:
    - pip install flakehell
    - flakehell lint --format=gitlab --output-file flakehell.json eta_utility/ test/
  artifacts:
    reports:
      codequality: flakehell.json

license_scanning_local:
  extends: license_scanning
  before_script:
    - echo ""
  stage: check
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

secret_detection_local:
  extends: secret_detection
  before_script:
    - echo ""
  stage: check
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

test:
  stage: test
  script:
    - pip install pytest pytest-cov
    - pytest --cov

# build the sources
build:
  stage: deploy
  script:
    - pip install build twine
    - python -m build --sdist --wheel
    - TWINE_PASSWORD=$CI_DEPLOY_PASSWORD TWINE_USERNAME=$CI_DEPLOY_USER python -m twine upload --repository-url https://$CI_SERVER_HOST/api/v4/projects/$CI_PROJECT_ID/packages/pypi dist/*
  artifacts:
    name: "eta_utility-build-$CI_COMMIT_REF_NAME-$CI_JOB_STATUS"
    paths:
      - dist/
      - eta_utility.egg-info/
  rules:
    - if: $CI_COMMIT_BRANCH == "master"

# Create sphinx html documentation
pages:
  stage: deploy
  script:
    - apt-get update
    - apt-get --yes install libgl1-mesa-glx
    - pip install sphinx sphinx-rtd-theme
    - cd docs
    - make html
    - mv _build/html ../public
  artifacts:
    name: "eta_utility-docs-$CI_COMMIT_REF_NAME"
    paths:
      - public/
  rules:
    - if: $CI_COMMIT_BRANCH == "master"

compile_fmu:
  stage: setup
  before_script:
    - echo ""
  script:
    - python -V  # Print out python version for debugging
    - python3 -m venv venv
    - source venv/bin/activate
    - pip install fmpy
    - apt-get update
    - apt-get --yes install zip
    - \[ ! -d $CI_PROJECT_DIR/fmu_extract ] && mkdir $CI_PROJECT_DIR/fmu_extract
    - unzip -u $CI_PROJECT_DIR/test/test_resources/test_fmu.fmu -d fmu_extract
    - cd fmu_extract/sources
    - gcc -c -I. -I$CI_PROJECT_DIR/venv/lib/python3.7/site-packages/fmpy/c-code -fPIC all.c && gcc -static-libgcc -shared -oout.so *.o
    - \[ ! -d ../binaries/linux64 ] && mkdir ../binaries/linux64
    - mv out.so ../binaries/linux64/test_fmu.so
    - cd ..
    - zip -r ../test_fmu.fmu *
    - cd ..
    - rm -rf fmu_extract
  rules:
    - when: never
  cache:
    key: none
